{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "# from nba_api.stats.static import players, teams\n",
    "# from nba_api.stats.endpoints import CommonTeamRoster, playercareerstats, leagueseasonmatchups, leaguegamefinder, boxscoresummaryv2, boxscoreplayertrackv2, boxscoretraditionalv2, cumestatsteam, leaguestandings, cumestatsteamgames, leaguegamelog\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import cupy as np \n",
    "import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.error import HTTPError\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(func, retries=3):\n",
    "    # Use decorator @retry when making requests to the API. \n",
    "    def retry_wrapper(*args, **kwargs):\n",
    "        attempts = 0\n",
    "        while attempts < retries:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.request.status_code == 429:\n",
    "                    # sports reference websites, of which basketball_reference is a subsidiary, does not like bot traffic.\n",
    "                    # Limits to 20 requests/min, and a 1 hour ban if violated. \n",
    "                    print(e, 'why did i request so much. :(')\n",
    "                    time.sleep(3600)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(e)\n",
    "                time.sleep(30)\n",
    "                attempts += 1\n",
    "\n",
    "    return retry_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry #scrape_game(link)\n",
    "def scrape_game(link: str):\n",
    "    '''\n",
    "    Returns a pandas dataframe containing the box score of both teams. \n",
    "    game_link: https://www.basketball-reference.com{link}\n",
    "    '''\n",
    "    response = requests.get(f'https://www.basketball-reference.com{link}')\n",
    "    \n",
    "    soup = bs.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Two tables holding stats. One for each team. Want stats for each player for each game.\n",
    "    basic_stats = ['mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'plus_minus', 'reason']\n",
    "    tables = soup.find_all('table', {'class': 'sortable stats_table', 'id': re.compile('box-\\w{3}-game-basic')})\n",
    "    all_player_stats = []\n",
    "    \n",
    "    for table in tables:\n",
    "        team_abbr = table['id'].split('-')[1]\n",
    "        table_body = table.find('tbody')\n",
    "        table_rows = table_body.find_all('tr', {'class': None})\n",
    "        for row in table_rows:\n",
    "            player_stats = {}\n",
    "            # Stats which are available in the table\n",
    "            for stat in basic_stats:    \n",
    "                potential_stat = row.find('td', {'data-stat': stat})\n",
    "                if potential_stat != None:\n",
    "                    player_stats[stat] = potential_stat.get_text()\n",
    "\n",
    "            # Convert mp to float\n",
    "            if 'mp' in player_stats and player_stats['mp'] != '':\n",
    "                mp = player_stats['mp'].split(\":\")\n",
    "                minutes = int(mp[0])\n",
    "                seconds = int(mp[1])\n",
    "                mp = minutes + seconds/60\n",
    "                player_stats['mp'] = mp\n",
    "\n",
    "            # Not so easy stats :(         \n",
    "            potential_player_name = row.find('th', {'data-stat': 'player'}).find('a')   \n",
    "            if potential_player_name != None:\n",
    "                player_stats['player'] = potential_player_name.get_text()\n",
    "            else:\n",
    "                player_stats['player'] = 'why'\n",
    "            player_stats['link'] = link\n",
    "            game_date = link.split('/')[-1].split('.')[0][:-4] #link takes form /boxscores/YYYYMMDD0(3-digit home abbrev).html\n",
    "            player_stats['game_date'] = datetime.strptime(game_date, '%Y%m%d').date()\n",
    "            player_stats['team'] = team_abbr\n",
    "            player_stats['location'] = link.split('/')[-1].split('.')[0][-3:]\n",
    "\n",
    "            # Convert empty fields and Nan to None\n",
    "            for stat in player_stats:\n",
    "                if player_stats[stat] == '' or player_stats[stat] == 'NaN':\n",
    "                    player_stats[stat] = None\n",
    "\n",
    "            # convert to ints/doubles if appropriate\n",
    "            ints = ['fg', 'fga', 'fg3', 'fg3a', 'ft', 'fta', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'plus_minus']\n",
    "            doubles = ['fg_pct', 'fg3_pct', 'ft_pct']\n",
    "            for stat in ints:\n",
    "                if stat in player_stats and player_stats[stat] != None:\n",
    "                    player_stats[stat] = int(player_stats[stat])\n",
    "            for stat in doubles:\n",
    "                if stat in player_stats and player_stats[stat] != None:\n",
    "                    player_stats[stat] = float(player_stats[stat])\n",
    "\n",
    "            all_player_stats.append(player_stats)\n",
    "\n",
    "    cur_game = pd.DataFrame(all_player_stats)\n",
    "    cur_game.fillna(0, inplace=True)\n",
    "    return cur_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry # find_months_with_games\n",
    "def find_months_with_games(season):\n",
    "    '''\n",
    "    Make sure we only request for months that exist in a season. \n",
    "    '''\n",
    "    months = []\n",
    "    response = requests.get(f'https://www.basketball-reference.com/leagues/NBA_{season}_games.html')\n",
    "    soup = bs.BeautifulSoup(response.text, 'html.parser')\n",
    "    filter = soup.find('div', {'class': 'filter'})\n",
    "    for month in filter.find_all('div'):\n",
    "        months.append(month.find('a').text.replace(' ', '-'))\n",
    "\n",
    "    # Need to lowercase them for some reason\n",
    "    months = [mo.lower() for mo in months]\n",
    "    return months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry # find_games_in_month(season, month)\n",
    "def find_games_in_month(season, month):\n",
    "    '''\n",
    "    Returns the links to all games in that season and month\n",
    "    '''   \n",
    "    try:\n",
    "        response = requests.get(f'https://www.basketball-reference.com/leagues/NBA_{season}_games-{month}.html')\n",
    "        response.raise_for_status()\n",
    "        soup = bs.BeautifulSoup(response.text, 'html.parser')\n",
    "        table_holding_games = soup.find('tbody') # Only one tbody tag on the page.\n",
    "        links = table_holding_games.find_all('td', {'data-stat': 'box_score_text'})\n",
    "        # Some games will be scheduled but not yet played. \n",
    "        links = [link for link in links if link is not None]\n",
    "        links = [link.find('a') for link in links if link.find('a') is not None]\n",
    "        links = [link.get('href') for link in links]\n",
    "        return(links)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            print(f'No games were played in {month} during the {season-1}-{season} season')\n",
    "            print(f'https://www.basketball-reference.com/leagues/NBA_{season}_games-{month}.html')\n",
    "        else:\n",
    "            raise\n",
    "    except Exception as e:\n",
    "        print(e.response.status_code)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry # scrape_games_in_month(season, month)\n",
    "def scrape_games_in_month(season, month):\n",
    "    '''\n",
    "    Scrapes all games in a given season and month\n",
    "    '''\n",
    "    game_links = find_games_in_month(season, month)\n",
    "    all_game_dataframes = []\n",
    "    for link in game_links:\n",
    "        game_stats = scrape_game(link)\n",
    "        all_game_dataframes.append(game_stats)\n",
    "        time.sleep(3) # 20 requests/min timer. \n",
    "    \n",
    "    return pd.concat(all_game_dataframes, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_season(season):\n",
    "    '''\n",
    "    Scrapes a seasons worth of data from basketball_reference. \n",
    "    Saves into csv files. 'season-month.csv'\n",
    "    Does not work for season 2019-2020 due to bubble crap :(. Just do it manually copium.\n",
    "    Returns a pandas dataframe \n",
    "    '''\n",
    "    months = find_months_with_games(season)\n",
    "    for month in months:\n",
    "        if month in ['september', 'october', 'november', 'december']:\n",
    "            # Actually the prior year because season are years (season-1) to season. 2019-2020 fucked because covid \n",
    "            year = season - 1\n",
    "        else:\n",
    "            year = season\n",
    "        \n",
    "        if os.path.exists(f'data/{year}') and os.path.exists(f'data/{year}/{year}-{month}.csv'):\n",
    "            print(f'{year}-{month} already exists. Current time: ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            pass        \n",
    "        else:\n",
    "            print(f'Scraping games in {year}-{month}. Current time: ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            games = scrape_games_in_month(season, month) # func works off season not year.\n",
    "            if not os.path.exists(f'data/{year}'):\n",
    "                os.mkdir(f'data/{year}')\n",
    "            games.to_csv(f'data/{year}/{year}-{month}.csv', index=False)\n",
    "\n",
    "# scrape_season(2020)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-october already exists. Current time: 12:44:37\n",
      "2022-november already exists. Current time: 12:44:37\n",
      "2022-december already exists. Current time: 12:44:37\n",
      "2023-january already exists. Current time: 12:44:37\n",
      "2023-february already exists. Current time: 12:44:37\n",
      "2023-march already exists. Current time: 12:44:37\n",
      "2023-april already exists. Current time: 12:44:37\n",
      "2023-may already exists. Current time: 12:44:37\n",
      "2023-june already exists. Current time: 12:44:37\n",
      "2021-october already exists. Current time: 12:44:37\n",
      "2021-november already exists. Current time: 12:44:37\n",
      "2021-december already exists. Current time: 12:44:37\n",
      "2022-january already exists. Current time: 12:44:37\n",
      "2022-february already exists. Current time: 12:44:37\n",
      "2022-march already exists. Current time: 12:44:37\n",
      "2022-april already exists. Current time: 12:44:37\n",
      "2022-may already exists. Current time: 12:44:37\n",
      "2022-june already exists. Current time: 12:44:37\n",
      "2020-december already exists. Current time: 12:44:37\n",
      "2021-january already exists. Current time: 12:44:37\n",
      "2021-february already exists. Current time: 12:44:37\n",
      "2021-march already exists. Current time: 12:44:37\n",
      "2021-april already exists. Current time: 12:44:37\n",
      "2021-may already exists. Current time: 12:44:37\n",
      "2021-june already exists. Current time: 12:44:37\n",
      "2021-july already exists. Current time: 12:44:37\n",
      "2020-october-2019 already exists. Current time: 12:44:38\n",
      "2019-november already exists. Current time: 12:44:38\n",
      "2019-december already exists. Current time: 12:44:38\n",
      "2020-january already exists. Current time: 12:44:38\n",
      "2020-february already exists. Current time: 12:44:38\n",
      "2020-march already exists. Current time: 12:44:38\n",
      "2020-july already exists. Current time: 12:44:38\n",
      "2020-august already exists. Current time: 12:44:38\n",
      "2019-september already exists. Current time: 12:44:38\n",
      "2020-october-2020 already exists. Current time: 12:44:38\n",
      "2018-october already exists. Current time: 12:44:38\n",
      "2018-november already exists. Current time: 12:44:38\n",
      "2018-december already exists. Current time: 12:44:38\n",
      "2019-january already exists. Current time: 12:44:38\n",
      "2019-february already exists. Current time: 12:44:38\n",
      "Scraping games in 2019-march. Current time: 12:44:38\n",
      "Scraping games in 2019-april. Current time: 12:57:48\n"
     ]
    }
   ],
   "source": [
    "for year in range(2023, 2000, -1):\n",
    "    scrape_season(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
